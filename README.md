# COAI LinkedIn Content Pipeline

An AI-powered content generation system that creates engaging LinkedIn posts about AI safety, control, and mechanistic interpretability by combining insights from X.com discussions and arXiv papers.

## ğŸ¯ Project Goals

- Monitor X.com for discussions on technical AI governance, AI control, AI safety, and mechanistic interpretability
- Fetch and analyze relevant papers from arXiv (cs.AI, cs.CL categories)
- Generate authentic, engaging LinkedIn posts that don't sound artificial
- Identify potential podcast interviewees from LinkedIn network
- Increase visibility of COAI Research in the AI safety community

## ğŸ—ï¸ Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LiteLLM Router                           â”‚
â”‚  (Switches between Ollama, OpenAI, Claude, Gemini, etc.)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Data Collector â”‚   Content Pipeline    â”‚  LinkedIn Intel  â”‚
â”‚  - X.com Scannerâ”‚   - CrewAI Agents    â”‚  - Network Map   â”‚
â”‚  - arXiv Fetcherâ”‚   - Post Generator   â”‚  - Expert Finder â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/prof-schacht/coai-linkedin-content-pipeline.git
cd coai-linkedin-content-pipeline

# Set up environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install -r requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env with your API keys

# Run setup
python scripts/setup_database.py

# Start Ollama (for local LLMs)
docker-compose up -d ollama

# Run the pipeline
python scripts/daily_run.py
```

## ğŸ“ Project Structure

```
coai-linkedin-content-pipeline/
â”œâ”€â”€ docker-compose.yml          # Services configuration
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ litellm_config.py      # LLM routing configuration
â”‚   â”œâ”€â”€ agents_config.py       # CrewAI agents setup
â”‚   â””â”€â”€ topics_config.py       # AI safety topics configuration
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ collectors/
â”‚   â”‚   â”œâ”€â”€ arxiv_monitor.py   # arXiv paper fetcher (cs.AI, cs.CL)
â”‚   â”‚   â””â”€â”€ x_scanner.py       # X.com content scanner
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py      # Base agent class
â”‚   â”‚   â”œâ”€â”€ research_analyst.py # Analyzes papers and discussions
â”‚   â”‚   â”œâ”€â”€ content_strategist.py # Plans post structure
â”‚   â”‚   â”œâ”€â”€ linkedin_writer.py  # Generates authentic posts
â”‚   â”‚   â””â”€â”€ interview_scout.py  # Identifies podcast candidates
â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”œâ”€â”€ post_creator.py    # Assembles final posts
â”‚   â”‚   â””â”€â”€ authenticity_engine.py # Ensures natural tone
â”‚   â”œâ”€â”€ analyzers/
â”‚   â”‚   â”œâ”€â”€ network_mapper.py  # LinkedIn connection analysis
â”‚   â”‚   â””â”€â”€ expert_scorer.py   # Ranks potential interviewees
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ litellm_router.py  # LLM switching logic
â”‚       â””â”€â”€ cache_manager.py   # Response caching
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup_database.py      # Initial database setup
â”‚   â”œâ”€â”€ import_connections.py  # LinkedIn network import
â”‚   â””â”€â”€ daily_run.py          # Main execution script
â””â”€â”€ tests/
    â””â”€â”€ ...                    # Test files
```

## ğŸ”§ Key Features

### LiteLLM Integration
- Seamless switching between local (Ollama) and cloud LLMs
- Cost optimization with intelligent routing
- Fallback chains for reliability

### Data Collection
- **arXiv Monitor**: Daily checks of cs.AI and cs.CL categories
- **X.com Scanner**: Tracks discussions on AI safety topics
- **Cross-referencing**: Links papers mentioned in X.com posts

### CrewAI Agents
1. **Research Analyst**: Extracts insights from papers and discussions
2. **Content Strategist**: Plans engaging post structures
3. **LinkedIn Writer**: Creates authentic, non-robotic content
4. **Interview Scout**: Identifies experts in your network for podcasts

### Authenticity Features
- Personal writing style analysis
- Natural language variations
- Engagement elements (questions, observations)
- Smart mention suggestions

## ğŸ“Š Topics Monitored

- Technical AI Governance
- AI Control
- AI Safety
- Mechanistic Interpretability

## ğŸ¯ Use Cases

1. **Daily Content Generation**: Automated creation of 1-2 LinkedIn posts
2. **Expert Discovery**: Find potential podcast guests in your network
3. **Trend Analysis**: Identify emerging topics in AI safety
4. **Network Growth**: Connect with relevant professionals

## ğŸ”’ Security & Privacy

- API keys stored in environment variables
- No storage of private LinkedIn data
- Respects rate limits and ToS
- Local LLM option for sensitive content

## ğŸ“ˆ Success Metrics

- Post engagement rate
- Network growth
- Interview candidates identified
- COAI Research visibility

## ğŸ¤ Contributing

See issues for current tasks. We follow a simple PR workflow:
1. Pick an issue
2. Create a feature branch
3. Submit PR with tests
4. Code review and merge

## ğŸ“ License

MIT License - see LICENSE file

## ğŸ™ Acknowledgments

- Built for [COAI Research](https://coairesearch.org)
- Powered by CrewAI, LiteLLM, and arXiv
